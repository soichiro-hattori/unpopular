{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **A quick introduction to *TESS-CPM*** \n",
    "In this notebook we'll go through two examples of how to use *TESS-CPM* python library to extract \"de-trended\" FFI light curves.\\\n",
    "The library is still a work in progress so apologies for the inevitable bugs!\n",
    "\n",
    "The second example will be a supernova light curve (ASASSN-18tb) and might be relevant for those of you interested in **sources with long-term variability**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Causal Pixel Model (CPM)**\n",
    "I'll skip the details of how CPM works, but if you're interested you should take a look at the original papers ([Wang et al. 2016](https://ui.adsabs.harvard.edu/abs/2016PASP..128i4503W/abstract), [Wang et al. 2017](https://ui.adsabs.harvard.edu/abs/2017arXiv171002428W/abstract), and [Sch√∂lkopf et al. 2016](https://www.pnas.org/content/113/27/7391) for a more theoretical explanation).\n",
    "\n",
    "The core assumption behind CPM is that **common light curve variations across distant pixels are likely to be systematic effects**. This assumption is based on the idea that while we would **not** expect multiple distant stars to simultaneously show the same variation, *TESS* systematics (e.g., spacecraft jitter, scattered light) **would** simultaneously affect multiple distant pixels.\\\n",
    "Therefore, variations in a single pixel's light curve that can be modeled as a linear combination of many other *distant* pixels' light curves are probably systematic effects. CPM tries to capture these common variations in a single pixel so that it can be subtracted from the original pixel flux measurements to provide a \"de-trended\" pixel light curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Example 1 (TIC 395130640)**\n",
    "Let's start off by downloading a TESS FFI cutout using TESScut ([Brasseur et al. 2019](https://ui.adsabs.harvard.edu/abs/2019ascl.soft05007B/abstract)).\\\n",
    "*TESS-CPM* requires a reasonably large cutout since CPM works by using many other distant pixels as the model's features (regressors, predictors).\\\n",
    "We've recently been using 100x100 pixel cutouts, but the smallest cutout we've used was a 32x32 pixel cutout. One thing to keep in mind is that these FFI cutouts take up quite a bit of space (${\\sim} 250~\\mathrm{MB}$ for a 100x100 pixel cutout from one sector) and can also take a while to download.\\\n",
    "With that in mind, for this example I'll download a 50x50 pixel cutout of TIC 395130640."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since downloading FFI cutouts can take some time I've written a function around `Tesscut.download_cutouts()` to check whether you've already downloaded an FFI cutout with the same Right Ascension. If it doesn't find a match it'll go ahead and try to download the cutout. If it does finds a match in your directory it won't download the cutout and will let you know what the matching files are (unless you explicitly tell it to download by setting `force_download=True`).\n",
    "Other than the `force_download` keyword argument all the other arguments are just passed to the `Tesscut.download_cutouts()` method from the `astroquery.mast` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.mast import Tesscut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see what all the arguments are\n",
    "Tesscut.download_cutouts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.mast.utils import parse_input_location\n",
    "import os\n",
    "\n",
    "def check_before_download(coordinates=None, size=5, sector=None, path=\".\", inflate=True, objectname=None, force_download=False):\n",
    "\n",
    "    coords = parse_input_location(coordinates, objectname)\n",
    "    ra = f\"{coords.ra.value:.6f}\"\n",
    "    matched = [m for m in os.listdir(path) if ra in m]\n",
    "    if (len(matched) != 0) and (force_download == False):\n",
    "        print(f\"Found the following FITS files in the \\\"{path}/\\\" directory with matching RA values.\")\n",
    "        print(matched)\n",
    "        print(\"If you still want to download the file, set the \\'force_download\\' keyword to True.\")\n",
    "        return matched\n",
    "    else:\n",
    "        path_to_FFIs = Tesscut.download_cutouts(coordinates=None, size=size, sector=sector, path=path, inflate=inflate, objectname=objectname)\n",
    "        print(path_to_FFIs)\n",
    "        return path_to_FFIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_FFIs = check_before_download(size=50, objectname=\"TIC395130640\")  # This function can take a while to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the files are downloaded, we're ready to use `tess_cpm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_FFIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the observations from Sector 11.\n",
    "The current main interface to the `tess_cpm` package is through the `Source` class.  \n",
    "We'll initialize an instance of the `Source` class by passing the path to the FFI cutouts.  \n",
    "The `remove_bad` keyword argument specifies whether we want to remove the data points that have been flagged by the TESS QUALITY array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tess_cpm\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 10)\n",
    "\n",
    "s = tess_cpm.Source(path_to_FFIs[1], remove_bad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the median flux image of the FFI cutouts using the `plot_cutout()` method.\\\n",
    "It's usually a good idea to check the image to ensure you're not around the edges of the FFIs.\\\n",
    "The `l` and `h` keyword arguments set the lower and upper limits (as a percentage) of the range of fluxes to plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = s.plot_cutout(l=10, h=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing to do is specify the set of pixels (i.e., the aperture) we believe the source falls on.\\\n",
    "The source will roughly be at the center of the image if the cutouts were obtained by providing the source coordinates or the TIC to TESScut.\n",
    "  \n",
    "We can specify the set of pixels by using the `set_aperture()` method.  \n",
    "The current code only allows for a rectangular aperture. We're planning to allow the user to specify any aperture in the near future (end of September 2020).  \n",
    "We can define the extent of the rectangular aperture in the `set_aperture()` method using the `rowlims` and `collims` argument. For each of these arguments, just pass a list that specifies the lower and upper limits of the aperture. For example `rowlims=[50, 52]` means rows 50, 51, and 52 are in the aperture.  \n",
    "\n",
    "After specifying the aperture, we can visually check to see that your aperture is actually covering the pixels we're interested in using `plot_cutout()` again.  \n",
    "We can see our aperture by setting `show_aperture=True`. The overlayed aperture will make the pixels in the aperture look white. \n",
    "We can also pass the region of the cutour we'd like to see (instead of the entire cutout) by specifying the rows and columns in the same way we defined the aperture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.set_aperture(rowlims=[25, 26], collims=[25, 26])\n",
    "s.plot_cutout(rowlims=[20, 30], collims=[20, 30], show_aperture=True, l=10, h=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After specifying the aperture, we can check each pixel's light curves using the `plot_pix_by_pix()` method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = s.plot_pix_by_pix()  # Calling the method without any arguments plots the raw flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current CPM implementation works with all pixels' fluxes normalized such that they are zero-centered & median-divided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = s.plot_pix_by_pix(data_type=\"normalized_flux\")  # Setting `data_type=normalized_flux` will plot the zero-centered & median-divided flux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's specify our model.\\\n",
    "As mentioned at the beginning of this notebook, CPM's main idea is to model a single pixel's light curve as a linear combination of a bunch of other pixels' light curves.\\\n",
    "Since our FFI cutout isn't that large (50x50 pixels), let's model a single pixel as a combination of 64 pixel light curves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.add_cpm_model(exclusion_size=5, n=128, predictor_method=\"similar_brightness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check our above choices using the `plot_model()` method.\\\n",
    "In the plot belowe, the single white pixel is the target pixel (that we are trying to model), the shaded red area surrounding the target pixel is the *exclusion region* where predictor pixels are *not* allowed to be chosen from (since they may be pixels from the same source), and the other pixels in red are the chosen predictor pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = s.models[0][0].plot_model()  # This method allows us to see our above choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we're using 64 light curves to model a single light curve our model is very prone to overfit in its current form.  \n",
    "One of the ways of preventing overfitting is to constrain the flexibility of the model through regularization.  \n",
    "Currently we use L2 (Ridge) regularization. L2 regularization is equivalent to placing a Gaussian prior on each of the coefficients (see $\\S 2.1$ of [Luger et al. 2017](https://ui.adsabs.harvard.edu/abs/2018AJ....156...99L/abstract)).\\ \n",
    "We set the L2 regularization value using `set_regs()`. In the current implementation the value is the reciprocal of the prior variance (i.e., precision) on the coefficients.\\\n",
    "*Small values mean weak regularization and large values mean strong regularization*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While we 'should' be using cross-validation to set the regularization value, for this example we'll just use `0.1`.\n",
    "s.set_regs([0.1])  # The regularization value(s) need to be passed as a list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now perform least squares regression to model the target pixel's light curve with the `holdout_fit_predict()` method.\n",
    "In addition to regularization, we also use a train-and-test framework to prevent overfitting. In this framework we split the lightcurve into **k** contiguous sections and predict the **i-th** section with the coefficients obtained from training on all the other sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.holdout_fit_predict(k=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the CPM-subtracted flux for each pixel. Specifying `split=True` will plot each of the **k** sections in different colors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot_pix_by_pix(data_type=\"cpm_subtracted_flux\", split=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the original flux to what CPM was able to capture.\\\n",
    "We'll sum up the pixel light curves using the `get_aperture_lc()` method.\\\n",
    "For summing pixel light curves, the current default setting is to weight them by their median values (Thanks Ben!). If you don't want any weighting, you can simply specify `weighting=None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aperture_normalized_flux = s.get_aperture_lc(data_type=\"normalized_flux\")\n",
    "aperture_cpm_prediction = s.get_aperture_lc(data_type=\"cpm_prediction\", weighting=\"median\")\n",
    "plt.plot(s.time, aperture_normalized_flux, \".\", c=\"k\", ms=8, label=\"Normalized Flux\")\n",
    "plt.plot(s.time, aperture_cpm_prediction, \"-\", lw=3, c=\"C3\", alpha=0.8, label=\"CPM Prediction\")\n",
    "plt.xlabel(\"Time - 2457000 [Days]\", fontsize=30)\n",
    "plt.ylabel(\"Normalized Flux\", fontsize=30)\n",
    "plt.tick_params(labelsize=20)\n",
    "plt.legend(fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also sum up the CPM-subtracted fluxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_detrended_flux = s.get_aperture_lc(data_type=\"cpm_subtracted_flux\")\n",
    "plt.plot(s.time, apt_detrended_flux, \"k-\")\n",
    "# plt.plot(s.time, aperture_normalized_flux-aperture_cpm_prediction, \"r.\", alpha=0.2)  # Gives you the same light curve as the above line\n",
    "plt.xlabel(\"Time - 2457000 [Days]\", fontsize=30)\n",
    "plt.ylabel(\"CPM Flux\", fontsize=30)\n",
    "plt.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it seems like there's some oscillation in that light curve, we can check it out using the `lightkurve` package ([Lightkurve Collaboration 2018](https://ui.adsabs.harvard.edu/abs/2018ascl.soft12013L/abstract))!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightkurve as lk\n",
    "lc = lk.TessLightCurve(time=s.time, flux=apt_detrended_flux)\n",
    "lc.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = lc.to_periodogram(oversample_factor=2)\n",
    "fig, axs = plt.subplots(2, 1, figsize=(16, 16))\n",
    "pg.plot(ax=axs[0], c='k')\n",
    "pg.plot(ax=axs[1], c='k', view='period', scale=\"log\")\n",
    "# fig.suptitle(\"Periodogram\", fontsize=20, y=0.95)\n",
    "period = pg.period_at_max_power\n",
    "print(f\"Max Power Period: {period}\")\n",
    "lc.fold(period.value).scatter()\n",
    "plt.title(f\"Folded Lightcurve with Period: {period:.4f}\", fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Example 2 (ASASSN-18tb)**\n",
    "I'll do this today (September 8th, 2020)! It's more or less the same as what's already in the supernovae.ipynb but with a bit more explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_FFIs = check_before_download(coordinates=(64.525833,-63.615669), size=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
